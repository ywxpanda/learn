# search 的运行机制

    search执行时分为两个步骤(query then fatch)
        -query
            1.某个节点接受到了search的请求时，
            2.首先选择分片（包含完整的数据），并向分片发送search request
            3.被选中的分片户分别进行查询并排序，返回from+size个文档id和排序值
            4.然后node把所有节点返回的文档进行排序，选取from 到 from+size个文档的id
        -fetch
            1.通过search查询到的文档id去获取对应shard上文档数据的详情（multi_get请求）
            2.分片返回文档的详细数据
            3.拼接返回结果并返回给用户

## 相关性算分问题

    相关性算分在shard于shard之间是相互独立的，意味着每个单词在不同的分片上的IDF值是不一样的，最终导致每个shard上的相关性算分不准确

    解决思路：
        1.设置number_of_shards为1，文档数量较少时可以使用， 但是会导致查询速度慢
        2.使用DFS query-then-fatch的查询方式
            在拿到所有的文档之后再进行一次完整的相关性算分，消耗更多的cpu和内存，效率低下

## 排序

    es默认采用相关性算分排序，可以通过设置sort参数进行自定义排序规则
    字符串类型中text类型不能直接进行排序

    排序过程中倒排索引无法发挥作用，需要用到整排索引，也就是通过文档id和字段快速的获取文档的内容
    es提供了两种方式：
        1.fielddata默认禁用（只针对text类型）
        2.doc values默认启用除了text类型
        对比        fielddata          docValues
        创建时机    搜索时及时创建  于倒排索引创建的时间一致
        创建位置    JVM HEAP            disk
        优点     不会占用额外的磁盘资源  不会占用内存
        缺点    文档过多时，            减慢索引速度和占用额外的磁盘资源
                创建会话过多时间和
                占用过多内存

## 分页与遍历

    from size
    深度分页， from:990 size:10，会从每个分片上获取前一千个文档，然后汇总后再获取前一千个文档
    页数越深，处理的文档越多，占用的内存越多，耗时越长
    es可以通过index.max_result_window控制深度分页

## scroll

    可以以快照的方式解决深度分页的问题
    不能用来进行实时搜索
    尽量不要使用复杂的sort条件，使用_doc最为高效

## search after

    避免深度分页的性能问题，提供实时的下一页文档的获取功能
        -缺点不能使用from参数，也不能指定页数
        -只能查询下一页，不能查询上一页
        -使用简单
    第一次正常的查询
    之后获取查询结果中sort字段中的内容加入到“search_after”字段中

    如何避免深度分页的问题？
        通过唯一的排序值将每次要处理的文档数都控制在size以内

## 引用场景和对比

    类型            场景
    from/size      实时获取顶部的文档，需要自由的分页
    sroll          需要获取所有的文档或者导出数据
    search_after   需要全部的文档，且不需要自由的分页